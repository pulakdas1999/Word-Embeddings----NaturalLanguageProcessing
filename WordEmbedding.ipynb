{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing libraries**"
      ],
      "metadata": {
        "id": "FTWqMrYJ_Img"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWXeWFZc8QwP"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Sentence array**"
      ],
      "metadata": {
        "id": "i7Hfj3wX_CoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]"
      ],
      "metadata": {
        "id": "E2z6WLcl8gYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**One-hot encoding**"
      ],
      "metadata": {
        "id": "F0AV-R7w-_GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot encoding works just like hashing ==> where next empty slots are filled in based on the calculations done with hashing algorithms\n",
        "# Thereby, choosing a large vocabulary size is mandatory otherwise there will be  problem with fitting in of all the words and one word might overlap into another\n",
        "vocabulary_size = 100\n",
        "onehot_repr = [one_hot(words, vocabulary_size) for words in sentences]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVwi4EFT8jW7",
        "outputId": "9adef6b7-9a1e-42ec-e200-d01a89b071b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[98, 59, 24, 29], [98, 59, 24, 57], [98, 4, 24, 89], [71, 34, 34, 50, 91], [71, 34, 34, 50, 64], [35, 98, 58, 24, 29], [48, 48, 27, 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Padding extra zeroes to the start of words to make them all of equal lengths**"
      ],
      "metadata": {
        "id": "DvpEPPUi_qzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_length = 8\n",
        "embedded_docs = pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6waA5RP580Ch",
        "outputId": "31a318b9-e649-4444-9d00-c3c6cf9e93de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0 98 59 24 29]\n",
            " [ 0  0  0  0 98 59 24 57]\n",
            " [ 0  0  0  0 98  4 24 89]\n",
            " [ 0  0  0 71 34 34 50 91]\n",
            " [ 0  0  0 71 34 34 50 64]\n",
            " [ 0  0  0 35 98 58 24 29]\n",
            " [ 0  0  0  0 48 48 27 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Reducing the numbers to a 10D embedding**"
      ],
      "metadata": {
        "id": "NWMgcF0PASnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = 10\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, dim, input_length = sent_length))\n",
        "model.compile(optimizer = 'adam', loss = 'mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXJ3--pI_z0Y",
        "outputId": "f36da1ae-9145-45db-dc5c-8aa5af103de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 10)             1000      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1000 (3.91 KB)\n",
            "Trainable params: 1000 (3.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Length of each sentence == length of model(predict)[0] ==> 8**"
      ],
      "metadata": {
        "id": "HNaJ5oAXBa_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This means that for '0' in '[ 0  0  0  0 98 59 24 29]' we have the embedding as '[-0.04056021  0.02638127 -0.00394828 -0.00419446  0.02237586  0.04525783 -0.02064885  0.01385346 -0.04558868  0.02009482]'\n",
        "# Similarly, for '29' in '[ 0  0  0  0 98 59 24 29]' we have the embedding as '[-0.02807672  0.02688465 -0.04748455 -0.00117822 -0.02232385 -0.01863257 0.04037025 -0.02319509  0.00152504  0.02576596]'\n",
        "# Also, notice that for all the four '0's, the embeddings are absolutely similar\n",
        "print(model.predict(embedded_docs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSc9SDcYA7Mq",
        "outputId": "0e8bc52d-c9a9-4eea-895e-9cdc1d06fa3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "[[-0.04056021  0.02638127 -0.00394828 -0.00419446  0.02237586  0.04525783\n",
            "  -0.02064885  0.01385346 -0.04558868  0.02009482]\n",
            " [-0.04056021  0.02638127 -0.00394828 -0.00419446  0.02237586  0.04525783\n",
            "  -0.02064885  0.01385346 -0.04558868  0.02009482]\n",
            " [-0.04056021  0.02638127 -0.00394828 -0.00419446  0.02237586  0.04525783\n",
            "  -0.02064885  0.01385346 -0.04558868  0.02009482]\n",
            " [-0.04056021  0.02638127 -0.00394828 -0.00419446  0.02237586  0.04525783\n",
            "  -0.02064885  0.01385346 -0.04558868  0.02009482]\n",
            " [-0.00058631  0.00024825  0.02992855  0.02244103 -0.00965991 -0.01010143\n",
            "   0.02492208  0.0213404   0.02707118  0.00097662]\n",
            " [ 0.00496878 -0.03892033 -0.02431269 -0.03617909  0.00283279  0.03314129\n",
            "   0.01415025 -0.02948108  0.03365351  0.04215961]\n",
            " [-0.00583934  0.04421267  0.00054066 -0.03793598  0.00558459  0.01656208\n",
            "  -0.03719988  0.02738718 -0.01282429  0.03746258]\n",
            " [-0.02807672  0.02688465 -0.04748455 -0.00117822 -0.02232385 -0.01863257\n",
            "   0.04037025 -0.02319509  0.00152504  0.02576596]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNjWcgtHBCQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}